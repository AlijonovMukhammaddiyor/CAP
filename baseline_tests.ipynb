{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!tar xvzf ../input/200-bird-species-with-11788-images/CUB_200_2011.tgz","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!head -70 CUB_200_2011/README","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tracemalloc\ntracemalloc.start()\nimport gc\nimport re\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\ntf.data.experimental.enable_debug_mode()\nimport pandas as pd\nimport os\nimport cv2\nimport time\nimport tensorflow_datasets as tfds\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\n\nassert len(tf.config.experimental.list_physical_devices('GPU')) > 0, \"No GPU found. Try to connect one...\" #https://github.com/BaranovMykola/Tensorflow2Snippets/blob/master/image_dataset.ipynb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT = r\"./CUB_200_2011\"\nIMAGES = ROOT + r\"images/\"\nCHANNEL_NUM = 3\nEXAMPLES_IN_CUB200 = 11788\n\nIMAGE_SIZE = 224\nNUM_CLASSES = 200\nCLASSES_OFFSET = 0\nBATCH_SIZE = 64","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT = r\"./CUB_200_2011\"\nIMAGES = ROOT + r\"images/\"\nCHANNEL_NUM = 3\nEXAMPLES_IN_CUB200 = 11788\n#\nIMAGE_SIDE = 224\nNUM_CLASSES = 200\nCLASSES_OFFSET = 0\nBATCH_SIZE = 64\n\n##################################################\n\ndef process_image(file_path): #https://github.com/BaranovMykola/Tensorflow2Snippets/blob/master/image_dataset.ipynb\n    img = tf.io.read_file(tf.strings.join((ROOT, \"images\", file_path), separator=r\"/\"))\n    img = tf.image.decode_jpeg(contents=img, channels=3)\n    img = tf.image.resize(img, (IMAGE_SIDE,)*2)\n    img /= 255.0\n    return img\n\n##################################################\n#Read Files To pd.DataFrame\nclasses            = pd.read_csv(f\"{ROOT}/classes.txt\",            sep=\" \", names=[\"class_id\", \"class_name\"],        index_col=\"class_id\")\nclasses            = list(classes[\"class_name\"])\n#\nimages             = pd.read_csv(f\"{ROOT}/images.txt\",             sep=\" \", names=[\"image_id\", \"path\"],              index_col=\"image_id\")\ntrain_test         = pd.read_csv(f\"{ROOT}/train_test_split.txt\",   sep=\" \", names=[\"image_id\", \"is_training_image\"], index_col=\"image_id\").applymap(bool)\nimage_class_labels = pd.read_csv(f\"{ROOT}/image_class_labels.txt\", sep=\" \", names=[\"image_id\", \"class_id\"],          index_col=\"image_id\")\n##############################\ndef log(val):\n    print(f\"LOG : {val}\")\n    return val\n\ntrain_test_ds = tf.data.Dataset.zip((\n    tf.data.Dataset.from_tensor_slices(train_test.is_training_image.to_numpy()), #Get IS_TRAIN indicator\n    tf.data.Dataset.from_tensor_slices(images.path.to_numpy()).map(process_image, num_parallel_calls=tf.data.AUTOTUNE), #Get paths and map them\n    tf.data.Dataset.from_tensor_slices(image_class_labels.class_id.to_numpy()) #Get labels\n)).filter(lambda is_train, image, label: label > CLASSES_OFFSET and label <= NUM_CLASSES + CLASSES_OFFSET) \\\n  .map(lambda is_train, image, label: (is_train, image, tf.one_hot(label-CLASSES_OFFSET-1, depth=NUM_CLASSES)), num_parallel_calls=tf.data.AUTOTUNE) #filter : get CLASS_NUM classes from some widow of with CLASSES_WINDOW_SELECTION_OFFSET; map : Subtract 1 and WINDOW_WIDTH to make indexes start with 0, and use One Hot\n\ntrain = train_test_ds \\\n    .filter(lambda is_train, *_ : is_train) \\\n    .map(lambda *x: x[1:], num_parallel_calls=tf.data.AUTOTUNE) \\\n    .cache() \\\n    .shuffle(buffer_size=EXAMPLES_IN_CUB200)\n\ntest = train_test_ds \\\n    .filter(lambda is_train, *_ : not is_train) \\\n    .map(lambda *x: x[1:], num_parallel_calls=tf.data.AUTOTUNE) \\\n    .batch(BATCH_SIZE, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE) \\\n    .prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train \\\n    .batch(BATCH_SIZE, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE) \\\n    .prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base = tf.keras.applications.Xception(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=None,\n        input_shape=(224, 224, 3),\n    )\n\nbase.trainable=False\n\n# model 1: acc: 0.5395833253860474\n# model = tf.keras.Sequential([\n#     base,\n#     tf.keras.layers.Flatten(),\n#     tf.keras.layers.Dense(units=NUM_CLASSES, activation=\"sigmoid\")\n# ])\n\n#model 2: 0.4833333194255829\n# model = tf.keras.Sequential([\n#     base,\n#     tf.keras.layers.GlobalAveragePooling2D(),\n#     tf.keras.layers.Flatten(),\n#     tf.keras.layers.Dense(units=NUM_CLASSES, activation=\"sigmoid\")\n# ])\n\n#model 3:0.5286458134651184\n# model = tf.keras.Sequential([\n#     base,\n#     tf.keras.layers.GlobalMaxPooling2D(),\n#     tf.keras.layers.Flatten(),\n#     tf.keras.layers.Dense(units=NUM_CLASSES, activation=\"sigmoid\")\n# ])\n\n#model 4:0.4487847089767456\nmodel = tf.keras.Sequential([\n    base,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.1),\n    tf.keras.layers.Dense(units=128, activation=\"relu\"),\n    tf.keras.layers.Dense(units=NUM_CLASSES, activation=\"sigmoid\")\n])\n\nLEARNING_RATE = 0.0001\nMOMENTUM = 0.99\nOPTIMIZER = tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE, momentum=MOMENTUM, nesterov=True)\n\nmodel.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(train, epochs=50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history[\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('fully_connected.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}